\section{Obstacles to Reproducibility in Computational Sciences}
\label{s:obstacles}

There are various obstacles to reproducibility, and many of these were
  discussed by speakers and participants during the week. 
The obstacles and challenges are related to different stages of scientific 
  endeavour and different aspects of reproducibility.
Amongst the obstacles and challenges that we identified are:

{\bf Incentives} -- even though, as outlined in Section~\ref{s:recomputation}, 
  the issue of reproducibility is
  currently actively discussed by the scientific community, 
  and the funding entities do campaign for
  openness in computational science (e.g., \cite{NSF}), 
  the prevalent impression from the discussions at 
  the summer school is that there is still a lot to be done to increase 
  awareness of how one can benefit from reproducibility.
Mechanisms that would reward those who deliver reproducible results are also
  still to become widespread.
It was reiterated during the school that the self-benefits 
  of reproducibility, such as increased productivity, are likely 
  a good enough reason to invest time on assuring it.
However, in general both the self-benefits and the benefits to the community
  are latent and perceptible only in the longer term.
Thus investing the time to offer reproducibility is difficult without
  approbation and endorsement from colleagues, collaborators, supervisors,
  reviewers and executives.
  
{\bf Prerequisites} -- offering reproducibility in computational
  science is linked with giving access to data and code, both of which may
  be subject to legal limitations due to intellectual property and
  data protection issues.
Sharing data may additionally be bound to ethical responsibility, for instance
  if the data contain personal records or other sensitive information.  
Even non-sensitive non-commercial data may not be readily redistributed
  without assuring proper ethical consent from the data originators.

{\bf Practicalities} -- there is definitely no consensus as to the
  best technique for facilitating reproducibility of computational
  experiments. 
The reasons are at least threefold. 
First, the wealth of nomenclature (replicate, recompute, reproduce, 
  rerun, repeat, reuse) indicates that the aims and the needs of researchers
  differ significantly.
Second, the technology advances and continuously offers new methods that can
  aid researchers in offering reproducible results.
Third, there are numerous tradeoffs to be made: 
  \begin{inparaenum}[(i)]
  \item embrace cutting edge or widespread technology; 
  \item offer standalone or integrable solutions; 
  \item prioritise independence or ease of reproduction; 
  \item disseminate reduced comprehensible datasets or avoid excluding any data;
  \item put efforts on automating experiments with already publishable results
  or move on to new experiments.
  \end{inparaenum}
    
{\bf Dissemination} -- even if all of the above obstacles are overcome, 
  distribution and long-term persistence of the reproducible experiments
  pose challenges.
First, finding a venue for long-term preservation of large datasets or even 
  moderately-sized virtual-machine based packages may be an issue.
This is especially the case if one aims at blending software and data
  dissemination with traditional academic publishing.
Second, given that one of the key aims of reproducibility in science
  is to offer independent verification, the amount of knowledge 
  needed to rerun an experiment has to be reasonably adapted to the
  target audience.
Interdisciplinarity is inherent in the idea of computational sciences that
  merge computational techniques with diverse domains of science.
Consequently, one has to take into account that the users who will attempt to
  reproduce the results of an experiment may be
  astronomers, biologists, chemists, geologists, linguists, mathematicians,
  oceanographers, physicists, or statisticians.
Last but not least, dissemination of data, and especially of executable
  programs is subject to security issues associated with both the security
  of computer systems and the safety of the personal data of the researchers who
  are preparing the experiment and reproducing the results.
