\section{Case study \#1: Ethical requirements for recomputation}
\label{s:group1}

Human subjects research involves the collection of data through interaction
with individuals, or through collection of personally identifiable
information. Such research poses specific barriers to reproducibility. In
fields such as human-computer interaction (HCI), there are few replications of
previous work, attributable to a culture that does not reward
reproducibility, difficulty in replicating interaction techniques when
materials are not shared, and an emphasis on formative work which proposes new
techniques over summative work~\cite{hornbaek:replications}.

In the first of our case studies, we look at one specific challenge to reproducibility in HCI
research: capturing and disseminating the ethical requirements of an
experiment, such that others may better replicate the procedures of a
study. What we wish to make possible is the following scenario: 

\renewcommand{\labelenumi}{Step \arabic{enumi}:}
\begin{enumerate}
\item Alice undertakes an experiment where she collects human data. 
\item Alice then analyses those data and publishes an academic paper.
\item To comply with recomputation standards Alice then creates a VM 
which contains the data she collected and scripts to create the statistics
used in the paper. She includes an ethics specification which enumerates
key methodological details and ethical considerations,
and places the VM on recomputation.org. 
\item Bob reads Alice's research paper and is interested in comparing her work to his own.
\item Bob goes to recomputation.org and downloads the VM.
He recomputes all of Alice's experiments in order to verify the analysis in her paper.
\item Bob compares the data Alice has provided with his own and publishes his own paper.
From Alice's ethics specification, he can directly compare ethical considerations to account
for any methodological differences.
\item To comply with recomputation standards Bob then creates a VM which contains 
the data he collected and Alice's data and scripts to create the statistics used in the paper. He includes his own ethics specification which can be directly compared to Alice's for
the benefit of any further replications, 
then places this VM on recomputation.org.
\end{enumerate}
\renewcommand{\labelenumi}{\arabic{enumi}}

We evaluate the ethics requirements procedures of ten universities to
determine a minimum specification for reporting ethical considerations.

\subsection{Background}
Human subjects research often involves the collection
of sensitive identifiable data about participants. To ensure participants are
not placed at undue risk by the conduct of an experiment, an increasingly
rigorous process of oversight of the ethical conduct of research institutions
has emerged in recent decades in many countries, particularly the US, where
institutional review boards (IRB) have been charged with reviewing all
clinical and human subjects research in line with federal regulations, with
significant penalties for institutions if ethics violations occur. Each
institution, however, has freedom to implement IRB processes as they see fit
so long as such regulations are upheld. This leads to great inconsistencies
between the expectations of institutions, and the processes researchers must
engage with in order for research protocols to be approved.

Internationally, the situation is even more variable. In the UK, research
councils mandate that ethics be considered in order to receive funding, but the
conduct of individual ethics committees is not regulated. Some countries may
not impose any requirements at all upon institutions.

Such variety in the conduct of ethical approval between institutions a
represents a significant barrier to reproducibility in HCI research. If a
researcher wishes to replicate a HCI experiment which uses human subjects
data, they will usually need to seek ethical approval from their own
institution. In our recent work, a survey of 505 papers using online social network
(OSN) data found that only 2\% of papers disclose any of the ethical
considerations of their work~\cite{hutton:reproducibility}.

As researchers do not routinely disclose the protocol which
received IRB approval, attempted replications may miss crucial details
necessary to conduct the experiment, and to provide to IRB when seeking
ethical approval, which can reduce the correctness of a replication.

With IRBs and ethics boards operating largely independently with little policy
coordination, there is no standardisation of ethics procedures.

Indeed, reproducibility has only recently been considered an important
ambition for HCI researchers, with nascent efforts including RepliCHI, which
has operated as a CHI workshop since 2013~\cite{wilson:2013}. Despite such efforts however, the
wider community has not considered these ethical challenges in detail.

Next, we assess the state of the art in ethics procedures to determine what
commonalities exist between institutional requirements. From this, we aim to
derive a minimum ``ethical specification'', encoding fundamental
methodological details to help researchers replicate procedures and ethical
details, and to make it easier to replicate applications to other IRBs, with
the ambition of such specifications being routinely attached to HCI
experiments.


\subsection{Comparison of Ethical Requirements across Universities}

To understand the state of ethics procedures between institutions, we
collected ethics applications forms for ten universities located in the UK,
EU, USA, and Asia. A range of locations were chosen and a mixture of both
large research intensive and smaller institutions to capture a range of
cultural and regulatory expectations, which we expect will manifest in
different procedures. All forms collected were derived from publicly
accessible sources, except for one supplied by the authors. This is in itself
a significant barrier to reproducibility. Without making procedures publicly
available, there can be no external scrutiny about the appropriateness of some
institution's procedures, which makes it more difficult to derive standards.

For each form, two researchers independently coded each field, accounting for
differences in wording between forms so long as each attribute asked for the
same atomic information. Where one form requests expanded information
pertaining to a previously identified attribute, this was considered a
\emph{sub-attribute}. After independently coding the forms, the two researchers
discussed any discrepancies to arrive at a set of 145 unique attributes,
encompassing generic details, such as contact details of co- investigators,
methodological details, and institution-specific requirements, often for
insurance and liability purposes. Of these fields, only two were common to all
ten ethics forms --- the name of the principal investigator, and whether
informed consent was sought. This intersection was significantly smaller than
anticipated, and clearly does not constitute a useful minimum ethical
specification. It does however reveal two interesting properties. It confirms
our intuition that ethical procedures vary greatly between institutions, while
also identifying perhaps the single most important objective of the ethics
process: to ensure participants have given informed consent to participate in
an experiment.

% \begin{figure}
% \begin{minipage}{\linewidth}
% <<echo=FALSE,fig=TRUE>>=
% library(reshape)
% library(ggplot2)
% maps_data <- read.table("maps_dataframe",header=T)
% maps_melt <- melt(maps_data)
% maps_frame <- as.data.frame(table(maps_melt$Field))
% maps_frame <- maps_frame[order(-maps_frame$Freq),]
% tag_factor <- factor(maps_frame$Var1, levels=maps_frame$Var1)
% p <- ggplot(maps_frame, aes(x=tag_factor, y=Freq)) + geom_bar(stat = "identity",fill="slateblue4",colour="slateblue1") + scale_x_discrete(breaks=NULL,name="Fields") + scale_y_discrete(name="Frequency")
% print(p)
% @
% \caption{\label{p:ethicsFreq}Histogram showing frequency distribution of fields in ethics applications}
% \end{minipage}
% \end{figure}


\begin{figure}

\begin{minipage}{\linewidth}
\begin{center}
<<echo=FALSE,fig=TRUE,height=5,width=7>>=
library(reshape)
library(ggplot2)
library(plyr)
maps_data <- read.table("maps_dataframe_primary",header=T)
maps_melt <- melt(maps_data)
attach(maps_melt)
maps_table <- table(Field)
maps_table <- rev(sort(maps_table))
maps_frame <- as.data.frame(table(maps_melt$Field,maps_melt$Type))
maps_frame <- maps_frame[order(-maps_frame$Freq),]
#$ only to shut up my syntax highlighter

maps_frame_cdf <- melt(maps_frame)
maps_frame_cdf <- ddply(maps_frame_cdf, .(variable), transform, ecd=ecdf(value)(value))
maps_frame_cdf <- subset(maps_frame_cdf,value!=0)

p <- ggplot(maps_frame_cdf, aes(x=value)) + scale_x_continuous(breaks=1:10,name="Forms") + scale_y_continuous(name="Field frequency") + stat_ecdf(aes(colour=Var2)) + theme(panel.background = element_rect(fill = "transparent",colour = "black"),text=element_text(size=18)) + scale_colour_manual(name="Field type",labels=c("High level","Sub-attribute"),values=c("#13456f", "#e02828"))
print(p)
@
\end{center}
\caption{\label{p:ethicsFreq}CDF showing the distribution of high-level and sub-attributes across the ethics forms examined. Half of high-level attributes only occur in one form, while no sub-attributes appear in more than seven forms.}

\end{minipage}
\end{figure}


Figure~\ref{p:ethicsFreq} shows the distribution of attributes across the ten
forms we examined for both high-level and sub-attributes. As shown, half of
high-level attributes only appear in one form, while 60\% of sub-attributes
are unique to one form. For example, while 60\% of forms ask whether
participants receive financial compensation (high level), only one asks
whether co-investigators are compensated (sub-attribute). We are most
interested in the unique high-level attributes that emerge, as it is important
to discern between questions which capture institution-specific requirements,
or may constitute important issues which other IRBs ought to consider. We find
instances of both in our results. For example, while UCL are the only
institution to ask whether their own students are participants in the research
(we assume for liability reasons), surprisingly they are the only university
to ask outright whether health and safety precautions have been considered.
Interestingly, only Aga Khan University in Pakistan asks whether the study is
a replication of a previous experiment.

\subsection{Proposed ethics specification}
Given the small intersection of attributes in our study, we isolate the twenty
most common high-level attributes -- those which occurred in six or more of
the ten forms we examined. We combine any semantically similar fields to
produce the following set of 15 attributes, presented in descending order of
frequency.

\begin{itemize}
	\item Was consent sought?
	\item Was deception involved?
	\item Project title
	\item Study duration
	\item Are there risks to participants?
	\item Justify use of vulnerable participants
	\item PI contact details
	\item Funding body information
	\item Is likely to induce participant stress?
	\item Summarise research proposal/experimental methods
	\item Are supplementary documents attached? (consent forms, briefing info etc.)
	\item Are participants financially compensated?
	\item Is study clinical?
	\item Supervisor name
	\item Describe ethical issues 
\end{itemize}

This set of attributes covers a range of fundamental methodological details,
many of which can be encoded in a consistent fashion and attached as metadata
to support replications. In further work, we will demonstrate whether this set
of attributes is sufficient to capture key methodological details, which we
cannot assert from this strictly frequency-based exercise.

\subsubsection{Limitations}
This analysis is not intended as a rigorous survey of ethics procedures
internationally. The selection of institutions is inherently biased, as we are
only able to extract forms which are publicly accessible, a barrier to
reproducibility, and we have a particular emphasis on the UK in this study,
with six institutions represented. The intent of this exercise is not to make
statistical inferences about the state of the art in ethics review, but rather
to motivate the minimum set of attributes we recommend researchers disclose
when sharing their experimental methodologies. We also wish to raise awareness
of the importance of ethical procedures when considering reproducibility of
research.



