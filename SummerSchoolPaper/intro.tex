\section{Introduction}
\label{s:intro}


We consider reproducibility in the computational sciences in this paper.  We
interpret computational sciences as including computer science, but also any
other science in which computational work plays an important role, such as
physics or psychology. The central hypothesis of this paper is that
reproducibility is a cornerstone of the scientific method, and should therefore
be a cornerstone of computational sciences. We ask to what extent this is true
and what challenges arise in reproducing work in computational sciences.

To study these questions, we performed four case studies that consider different
issues related to reproducibility in computational sciences.  Each case study
takes on a different aspect of reproducibility, identifies any problems
encountered, and discusses the points that they have raised.

An often-overlooked fact is that reproducibility in the computational sciences
is not only an issue of the actual computations, but also of preliminaries and
other setup that is not related to computation at all. The first case study asks
how reproducibility is affected by differing ethics requirements at different
universities. Ethics approval has to be obtained for any experiments involving
human subjects, such as the ones that are common in human-computer interaction
research, but different institutions put emphasis on different aspects. How
reproducible is research that is ``conditioned'' on one particular ethics form?

The second case study considers whether parallel and distributed computational
experiments are more or less reproducible than serial ones. Computational
experiments are at the core of a lot of research, especially in artificial
intelligence, where the motivation for this case study lies. In recent years,
multi-core and multi-processor machines have become increasingly prevalent. To
make use of this increased processing power, experiments need to utilise
multiple resources at once. But is this inherently detrimental to
reproducibility?

While computer science likely accounts for the majority of computational
experiments, they are becoming increasingly important in other areas. In physics
or chemistry for example, simulations of physical processes help scientists gain
insights. Our third case study is motivated by this fact and asks how
reproducible computational scientific experiments from disciplines other than
computer science are. We consider experiments from several research areas. Given
that researchers in other areas use computation only as a tool and may not be
as aware of issues related to reproducibility as computer scientists, does
reproducibility suffer?

Our final case study considers whether reproducible for one person is the same
as reproducible for another. It asks how reproducible the data analysis of a
published experiment in human-computer interaction where the author made
significant efforts to make it reproducible is. While it is reasonable to assume
that the author of an experiment can conduct it in a way that enables her or him
to do it again, having another person do it is an entirely different matter.
There may be implicit assumptions that are not specified, background knowledge
assumed, or environmental aspects unconsidered. Can a carefully prepared
experiment be recomputable by someone with no specific background in the area?

Most of the work for this paper was performed during the Summer School on
Experimental Methodology in Computational Science Research.\footnote{St
Andrews, Scotland, August 4-8, 2014,
\url{https://blogs.cs.st-andrews.ac.uk/emcsr2014/}}
Indeed, a highly
provisional first draft of this paper was completed by the end of the Summer
School~\cite{emcsr_arxiv_draft}, with ensuing weeks used in completing work and writing.  
The first three case studies
were selected by discussing the interests of participants and forming groups
and research questions around these. Therefore, these case studies were
performed by subsets of the authors. These case studies will be
presented below in Sections~\ref{s:group1}~--~\ref{s:group3}. The final case
study was led by a lecturer of the summer school, was performed by all
participants, and is presented in Section~\ref{s:group4}.

The case studies we consider are not exhaustive and no single one can give
complete answers. Instead, they shine spotlights on specific, important areas
related to the issue of reproducibility in computational sciences. Furthermore,
each raises interesting questions for future consideration by researchers
wishing to reproduce computational experiments.

Additionally, we consider the meta-level question of how reproducible this paper
itself is.  We have striven to make this paper open, reproducible, and
executable.
The entire edit history, including paper and many aspects of the
case studies, is available openly on
GitHub
and was indeed open from the start
of writing the paper.  
\cite{summerschoolpaper}
The paper has executable aspects through the integration of R
and \LaTeX\ via the R package Sweave~\cite{pineda-krch:sweave}, so that as the underlying
data change, new tables and figures can be regenerated automatically. Finally,
we have endeavoured to make it reproducible through measures such as providing
virtual machines for aspects of our work, not least a virtual machine in which
the paper itself can be rebuilt.
